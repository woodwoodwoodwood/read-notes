{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer 中的多头注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 64, 512])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(128, 64, 512) # (batch_size, seq_len, dimension)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "n_head = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5881,  0.2290,  0.2096,  0.7041],\n",
      "        [-0.4473,  0.2256, -1.2405, -0.1582],\n",
      "        [-0.8031,  0.4126, -1.2328,  1.0075],\n",
      "        [-0.7545, -0.9136,  0.6013, -1.2179]])\n",
      "tensor([[ True, False, False, False],\n",
      "        [ True,  True, False, False],\n",
      "        [ True,  True,  True, False],\n",
      "        [ True,  True,  True,  True]])\n",
      "tensor([[-1.5881,    -inf,    -inf,    -inf],\n",
      "        [-0.4473,  0.2256,    -inf,    -inf],\n",
      "        [-0.8031,  0.4126, -1.2328,    -inf],\n",
      "        [-0.7545, -0.9136,  0.6013, -1.2179]])\n"
     ]
    }
   ],
   "source": [
    "atten_score = torch.randn(4, 4)\n",
    "print(atten_score)\n",
    "mask = torch.tril(torch.ones(4, 4, dtype=bool))\n",
    "atten_score = atten_score.masked_fill_(mask == 0, -math.inf)\n",
    "print(mask)\n",
    "print(atten_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 64, 512])\n",
      "tensor([[[-0.7563,  0.2732, -0.1377,  ...,  0.6893, -0.0595, -0.0735],\n",
      "         [-0.5859,  0.0887, -0.0161,  ...,  0.2119, -0.0728,  0.2601],\n",
      "         [-0.3679, -0.2490,  0.0336,  ...,  0.1061,  0.1394,  0.2043],\n",
      "         ...,\n",
      "         [ 0.0496, -0.0639,  0.0130,  ...,  0.0110, -0.0519, -0.0672],\n",
      "         [ 0.0323, -0.0598,  0.0200,  ...,  0.0174, -0.0532, -0.0883],\n",
      "         [ 0.0031, -0.0553,  0.0055,  ...,  0.0079, -0.0467, -0.0916]],\n",
      "\n",
      "        [[ 0.2163, -0.2435,  0.1143,  ..., -0.0651, -0.4114, -0.1521],\n",
      "         [ 0.0284, -0.1171,  0.2203,  ...,  0.1296, -0.1959,  0.0220],\n",
      "         [-0.0879, -0.1645,  0.1377,  ...,  0.1798, -0.0933, -0.0904],\n",
      "         ...,\n",
      "         [ 0.0325, -0.0391,  0.0850,  ...,  0.0449, -0.1511,  0.0230],\n",
      "         [ 0.0219, -0.0243,  0.0599,  ...,  0.0269, -0.1197,  0.0151],\n",
      "         [-0.0336, -0.0580,  0.0721,  ...,  0.0541, -0.1078, -0.0214]],\n",
      "\n",
      "        [[ 0.1049, -0.1835, -0.6369,  ..., -0.2131, -0.0796, -0.0694],\n",
      "         [ 0.1828, -0.1460, -0.0487,  ..., -0.1178, -0.1833, -0.0716],\n",
      "         [ 0.2079, -0.1651,  0.0794,  ..., -0.1463, -0.0424, -0.1529],\n",
      "         ...,\n",
      "         [-0.0357,  0.0543,  0.0254,  ...,  0.0036, -0.1245,  0.0037],\n",
      "         [-0.0060,  0.0503,  0.0196,  ..., -0.0258, -0.0881,  0.0154],\n",
      "         [-0.0331,  0.0288,  0.0472,  ..., -0.0417, -0.0834,  0.0184]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0295,  0.1634, -0.0858,  ...,  0.5394, -0.1498, -0.1056],\n",
      "         [ 0.3455, -0.1137,  0.0558,  ...,  0.3391,  0.3166, -0.0386],\n",
      "         [ 0.0526, -0.2133,  0.1281,  ...,  0.3601,  0.2689, -0.0203],\n",
      "         ...,\n",
      "         [-0.0492, -0.1316,  0.0367,  ...,  0.0591, -0.1236,  0.0957],\n",
      "         [-0.0729, -0.1455,  0.0147,  ...,  0.0727, -0.1074,  0.0636],\n",
      "         [-0.0621, -0.1324,  0.0183,  ...,  0.0669, -0.0936,  0.0871]],\n",
      "\n",
      "        [[-0.6376, -0.2070, -0.0336,  ...,  0.2083,  0.1516,  0.2327],\n",
      "         [-0.4150, -0.0802,  0.0322,  ...,  0.0248,  0.1628,  0.2297],\n",
      "         [-0.2209, -0.1570,  0.0222,  ...,  0.0267,  0.1818, -0.0776],\n",
      "         ...,\n",
      "         [-0.0629, -0.0354,  0.0995,  ...,  0.1066,  0.0235, -0.0074],\n",
      "         [-0.0792, -0.1061,  0.1086,  ...,  0.0792,  0.0564, -0.0268],\n",
      "         [-0.0803, -0.0763,  0.0895,  ...,  0.1307,  0.0334,  0.0056]],\n",
      "\n",
      "        [[-0.0013, -0.3658, -0.2263,  ..., -0.2195, -0.1150, -0.2410],\n",
      "         [-0.0187, -0.2420,  0.0573,  ..., -0.2536, -0.2863, -0.2436],\n",
      "         [-0.0984, -0.0508,  0.1525,  ...,  0.0793, -0.3291, -0.0871],\n",
      "         ...,\n",
      "         [-0.0050, -0.0278,  0.0264,  ..., -0.0359, -0.0740, -0.0308],\n",
      "         [-0.0098, -0.0232,  0.0240,  ..., -0.0223, -0.0642, -0.0143],\n",
      "         [ 0.0082, -0.0595,  0.0023,  ..., -0.0032, -0.0697, -0.0086]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_head) -> None:\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.d_k = d_model // n_head\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.w_combine = nn.Linear(d_model, d_model)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, q, k, v):\n",
    "        batch_size, seq_len, dimension = q.shape\n",
    "        n_d = dimension // self.n_head\n",
    "        q, k, v = self.w_q(q), self.w_k(k), self.w_v(v)\n",
    "        q = q.view(batch_size, seq_len, self.n_head, n_d).permute(0, 2, 1, 3)\n",
    "        k = k.view(batch_size, seq_len, self.n_head, n_d).permute(0, 2, 1, 3)\n",
    "        v = v.view(batch_size, seq_len, self.n_head, n_d).permute(0, 2, 1, 3)\n",
    "\n",
    "        attn_score = q @ k.transpose(2, 3) / math.sqrt(n_d)\n",
    "        mask = torch.tril(torch.ones(seq_len, seq_len, dtype=bool))\n",
    "        attn_score = attn_score.masked_fill(mask == 0, float('-inf'))\n",
    "        attn_score = self.softmax(attn_score) @ v\n",
    "\n",
    "        atten_score = attn_score.permute(0, 2, 1, 3).contiguous().view(batch_size, seq_len, dimension)\n",
    "\n",
    "        output = self.w_combine(atten_score)\n",
    "        return output\n",
    "    \n",
    "multi_head_atten = MultiHeadAttention(d_model, n_head)\n",
    "output = multi_head_atten(X, X, X)\n",
    "print(output.shape)\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
